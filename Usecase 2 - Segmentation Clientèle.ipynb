{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6757b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta\n",
    "from time import time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "Very_Start = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c30de",
   "metadata": {},
   "source": [
    "### DEFINITION DE TOUS LES PARAMETRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1535cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param Does it save the figure ?\n",
    "save_fig = True\n",
    "\n",
    "\n",
    "# @param Connexion à la DB\n",
    "driver   = '{ODBC Driver 17 for SQL Server}'\n",
    "server   = 'E5591-9S6YMV2'\n",
    "username = 'WVN\\k.dubrulle'\n",
    "login    = ('DRIVER=' + driver + \n",
    "         ';SERVER='   + server + \n",
    "         ';Trusted_Connection=yes;')\n",
    "\n",
    "\n",
    "# @param Definition des table et colonnes --> Dépendent de la DB\n",
    "DB             = \"Archive2018_2019_prod\"\n",
    "TABLE_CONSO    = \"Consommateur\"\n",
    "TABLE_ENTETE   = \"Recette_entete_ticket\"\n",
    "TEMPS_ENTETE   = TABLE_ENTETE               + \".TEMPS.KEY_Date_reel_de_la_transaction\"\n",
    "NUMERO_ENTETE  = TABLE_ENTETE               + \".Numero_ticket\"\n",
    "TABLE_DETAIL   = \"Recette_detail_ticket\"\n",
    "TEMPS_DETAIL   = TABLE_DETAIL               + \".TEMPS.KEY_Date_reel_transaction\"\n",
    "NUMERO_DETAIL  = TABLE_DETAIL               + \".Numero_ticket\"\n",
    "TABLE_ARTICLE  = \"Article_meti_HIST\"\n",
    "TABLE_UNIVERS  = \"Univers\"\n",
    "\n",
    "\n",
    "# @param Variable influançant la sélection des données\n",
    "nbr_client     = -1           # Nombre de clients à sélectionner. MAX = 148188. -1 --> ALL\n",
    "client_tresh   = 20           # Nombre d'article que le client doit avoir acheter pour être mis dans un segment\n",
    "univers_tresh  = 10           # Nombre d'article acheté de l'univers pour qu'il soit pris en compte\n",
    "\n",
    "Standard_Norm  = False        # Défini si on utilise la Normalization Standard\n",
    "Standard_Tresh = 1            # Seuil d'acceptabilité des cluster en normalization standard\n",
    "MinMax_Norm    = True         # Défini si on utilise la Normalization Minmax\n",
    "MinMax_Tesh    = .3           # Seuil d'acceptabilité des cluster par défaut\n",
    "\n",
    "do_Elbow       = False        # Est-ce qu'on fait l'analyse des Elbow ou pas ?\n",
    "Kmin           = 2            # Nombre de cluster au début de l'analyse\n",
    "Kmax           = 50           # Nombre de cluster à la fin de l'analyse\n",
    "\n",
    "K              = 21           # Nombre de segment. K = 21 -> 10% client d'exclu ; K = 15 -> 15% client exclu ; K = 9 -> 20% exclu \n",
    "n_init         = 10           # Nombre de run du KMean pour trouver le meilleur min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "92a148cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CONSOMMATEUR.KEY  Consommateur.Numero_consommateur_freedelity  \\\n",
      "0                -1                                           -1   \n",
      "1                 1                                          100   \n",
      "2                 2                                      1000138   \n",
      "3                 3                                      1000303   \n",
      "4                 4                                      1000323   \n",
      "5                 5                                      1000350   \n",
      "6                 6                                      1000371   \n",
      "7                 7                                      1000484   \n",
      "8                 8                                      1000571   \n",
      "9                 9                                       100058   \n",
      "\n",
      "   Consommateur.Points  Consommateur.Visits  Consommateur.TotalCA  \\\n",
      "0                    0                    0                  0.00   \n",
      "1                  674                    0               1089.39   \n",
      "2                  287                    0                299.75   \n",
      "3                  504                    0                514.32   \n",
      "4                  987                    0               1104.62   \n",
      "5                    0                    0                  0.00   \n",
      "6                    0                    0                434.84   \n",
      "7                  698                    0                721.65   \n",
      "8                    0                    0                 21.86   \n",
      "9                    0                    0                  3.65   \n",
      "\n",
      "   Consommateur.TotalVisits  Consommateur.RFM_R  Consommateur.RFM_F  \\\n",
      "0                         0                   0                   0   \n",
      "1                        60                   4                   4   \n",
      "2                        23                   3                   4   \n",
      "3                        26                   5                   5   \n",
      "4                        63                   5                   4   \n",
      "5                         0                   1                   2   \n",
      "6                        16                   2                   5   \n",
      "7                        42                   5                   5   \n",
      "8                         2                   1                   3   \n",
      "9                         1                   2                   1   \n",
      "\n",
      "   Consommateur.RFM_M Consommateur.PreferedStoreNumber  ...  \\\n",
      "0                   0                               64  ...   \n",
      "1                   5                               -1  ...   \n",
      "2                   5                               -1  ...   \n",
      "3                   5                               -1  ...   \n",
      "4                   5                               -1  ...   \n",
      "5                   1                               -1  ...   \n",
      "6                   5                               -1  ...   \n",
      "7                   5                               -1  ...   \n",
      "8                   2                               -1  ...   \n",
      "9                   1                               -1  ...   \n",
      "\n",
      "  Consommateur.Optin Consommateur.Membre_New Consommateur.Membre_plus_d_un_an  \\\n",
      "0                  0                       0                                0   \n",
      "1                  0                       0                                0   \n",
      "2                  0                       0                                0   \n",
      "3                  1                       0                                0   \n",
      "4                  1                       0                                0   \n",
      "5                  1                       0                                0   \n",
      "6                  1                       0                                0   \n",
      "7                  1                       0                                0   \n",
      "8                  0                       0                                0   \n",
      "9                  1                       0                                0   \n",
      "\n",
      "  Consommateur.Membre_plus_d_un_mois Consommateur.Membre_New_Points  \\\n",
      "0                                  1                            0.0   \n",
      "1                                  0                            0.0   \n",
      "2                                  1                            0.0   \n",
      "3                                  0                            0.0   \n",
      "4                                  0                            0.0   \n",
      "5                                  0                            NaN   \n",
      "6                                  0                            0.0   \n",
      "7                                  0                            0.0   \n",
      "8                                  0                            NaN   \n",
      "9                                  0                            0.0   \n",
      "\n",
      "  Consommateur.Premiere_vente Consommateur.Derniere_vente  \\\n",
      "0                  20191210.0                  20201217.0   \n",
      "1                  20191225.0                  20210131.0   \n",
      "2                  20191212.0                  20201229.0   \n",
      "3                  20200809.0                  20210130.0   \n",
      "4                  20191218.0                  20210131.0   \n",
      "5                         NaN                         NaN   \n",
      "6                  20200425.0                  20200811.0   \n",
      "7                  20191212.0                  20210126.0   \n",
      "8                         NaN                         NaN   \n",
      "9                  20200306.0                  20200306.0   \n",
      "\n",
      "  Consommateur.Membre_plus_de_3_mois  Consommateur.Membre_plus_de_6_mois  \\\n",
      "0                                  0                                   0   \n",
      "1                                  0                                   0   \n",
      "2                                  0                                   0   \n",
      "3                                  0                                   0   \n",
      "4                                  0                                   0   \n",
      "5                                  0                                   0   \n",
      "6                                  1                                   0   \n",
      "7                                  0                                   0   \n",
      "8                                  0                                   0   \n",
      "9                                  0                                   1   \n",
      "\n",
      "   Consommateur.Membre_moins_d_un_mois  \n",
      "0                                    0  \n",
      "1                                    1  \n",
      "2                                    0  \n",
      "3                                    1  \n",
      "4                                    1  \n",
      "5                                    0  \n",
      "6                                    0  \n",
      "7                                    1  \n",
      "8                                    0  \n",
      "9                                    0  \n",
      "\n",
      "[10 rows x 40 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TEST Connexion\n",
    "conn = pyodbc.connect(login)\n",
    "\n",
    "df = pd.read_sql(\"SELECT TOP(10) [\"+TABLE_CONSO+\".KEY] FROM [\"+DB+\"].[DWH].[Dim_\"+TABLE_CONSO+\"]\", conn)\n",
    "print(df)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1612969",
   "metadata": {},
   "source": [
    "# SEGMENTATION DE LA CLIENTELE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1269884f",
   "metadata": {},
   "source": [
    "## Récupération des données correspondant aux clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c657f637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT [Article_meti_HIST.Univers.KEY] AS Univers\n",
      ",[Recette_entete_ticket.Consommateur.KEY] AS Consommateur\n",
      "FROM [Archive2018_2019_prod].[DWH].[Fact_Recette_detail_ticket]\n",
      "INNER JOIN [Archive2018_2019_prod].[DWH].[Fact_Recette_entete_ticket] \n",
      "ON    [Recette_detail_ticket.TEMPS.KEY_Date_reel_transaction] = [Recette_entete_ticket.TEMPS.KEY_Date_reel_de_la_transaction] \n",
      "AND   [Recette_detail_ticket.Numero_ticket] = [Recette_entete_ticket.Numero_ticket]\n",
      "INNER JOIN [Archive2018_2019_prod].[DWH].[Dim_Article_meti_HIST]\n",
      "ON [Recette_detail_ticket.Article_meti_HIST.KEY] = [Article_meti_HIST.KEY] \n",
      "WHERE [Recette_entete_ticket.Consommateur.KEY] > 0 \n",
      "Time Taken to load DB: ~172secondes\n",
      "10836528\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "sql_command = '''SELECT [''' + TABLE_ARTICLE + '''.''' + TABLE_UNIVERS + '''.KEY] AS ''' + TABLE_UNIVERS + '''\n",
    ",[''' + TABLE_ENTETE + '''.''' + TABLE_CONSO + '''.KEY] AS ''' + TABLE_CONSO + '''\n",
    "FROM ['''       + DB + '''].[DWH].[Fact_''' + TABLE_DETAIL + ''']\n",
    "INNER JOIN [''' + DB + '''].[DWH].[Fact_''' + TABLE_ENTETE + '''] \n",
    "ON    [''' + TEMPS_DETAIL  +'''] = [''' + TEMPS_ENTETE  + '''] \n",
    "AND   [''' + NUMERO_DETAIL +'''] = [''' + NUMERO_ENTETE + ''']\n",
    "INNER JOIN [''' + DB + '''].[DWH].[Dim_''' + TABLE_ARTICLE + ''']\n",
    "ON ['''    + TABLE_DETAIL  + '''.'''    + TABLE_ARTICLE + '''.KEY] = [''' + TABLE_ARTICLE + '''.KEY] \n",
    "WHERE [''' + TABLE_ENTETE  + '''.'''    + TABLE_CONSO   + '''.KEY] > 0 '''\n",
    "if nbr_client != -1:\n",
    "    sql_command +=  ''' AND [''' + TABLE_ENTETE  +'''.'''     + TABLE_CONSO   + '''.KEY] < '''  + str(nbr_client)\n",
    "\n",
    "print(sql_command)\n",
    "\n",
    "conn = pyodbc.connect(login)\n",
    "df_univers = pd.read_sql(sql_command, conn)\n",
    "conn.close()\n",
    "\n",
    "# environ 3min\n",
    "print(\"Time Taken to load DB: ~\" + str(int(time() - start)) + \"secondes\") \n",
    "nbr_data = len(df_univers)\n",
    "print(nbr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "20fba9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             344       144       148       151       461       328       183  \\\n",
      "11377   0.010753  0.026882  0.016129  0.048387  0.284946  0.134409  0.048387   \n",
      "30766   0.048193  0.072289  0.048193  0.000000  0.144578  0.012048  0.084337   \n",
      "62982   0.076923  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "97964   0.139130  0.026087  0.017391  0.017391  0.104348  0.034783  0.095652   \n",
      "61405   0.020000  0.240000  0.020000  0.060000  0.000000  0.180000  0.020000   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "63427   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000   \n",
      "147844  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "147454  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "144632  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "145875  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.250000   \n",
      "\n",
      "             403       418       331  ...  261  51   279  265  146  205  7    \\\n",
      "11377   1.000000  0.053763  0.091398  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "30766   0.650602  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "62982   0.769231  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "97964   0.043478  0.000000  0.113043  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "61405   0.860000  0.020000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...          ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "63427   0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "147844  0.500000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "147454  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "144632  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "145875  0.500000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "        479  390  36   \n",
      "11377   0.0  0.0  0.0  \n",
      "30766   0.0  0.0  0.0  \n",
      "62982   0.0  0.0  0.0  \n",
      "97964   0.0  0.0  0.0  \n",
      "61405   0.0  0.0  0.0  \n",
      "...     ...  ...  ...  \n",
      "63427   0.0  0.0  0.0  \n",
      "147844  0.0  0.0  0.0  \n",
      "147454  0.0  0.0  0.0  \n",
      "144632  0.0  0.0  0.0  \n",
      "145875  0.0  0.0  0.0  \n",
      "\n",
      "[59656 rows x 428 columns]\n",
      "Time Taken to load Dataframe: ~109secondes\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "dict_client_univ = {}\n",
    "\n",
    "for i in range(nbr_data):\n",
    "    univ   = df_univers[TABLE_UNIVERS][i]\n",
    "    client = df_univers[TABLE_CONSO][i]\n",
    "    if univ == -1:\n",
    "        continue\n",
    "    \n",
    "    if not client in dict_client_univ:\n",
    "        dict_client_univ[client] = {}\n",
    "        \n",
    "    if not univ in dict_client_univ[client]:\n",
    "        dict_client_univ[client][univ] = 0\n",
    "    dict_client_univ[client][univ] += 1\n",
    "\n",
    "to_remove = []\n",
    "for k,v in dict_client_univ.items():\n",
    "    if sum(v.values()) < client_tresh:\n",
    "        to_remove.append(k)\n",
    "    else:\n",
    "        maxi = max(v.values())\n",
    "        dict_client_univ[k] = {key:value/maxi for key,value in v.items()}\n",
    "\n",
    "for k in to_remove:\n",
    "    del dict_client_univ[k]\n",
    "        \n",
    "    \n",
    "clients_data = pd.DataFrame(index = dict_client_univ.keys(),\n",
    "                        data = dict_client_univ.values())\n",
    "clients_data = clients_data.replace(float('NaN'), 0)\n",
    " \n",
    "print(clients_data)\n",
    "\n",
    "# environ 10s * nbr_client/10.000\n",
    "print(\"Time Taken to load Dataframe: ~\" + str(int(time() - start)) + \"secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "723f31d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             344       144       148       151       461       328       183  \\\n",
      "11377   0.010753  0.026882  0.016129  0.048387  0.284946  0.134409  0.048387   \n",
      "30766   0.048193  0.072289  0.048193  0.000000  0.144578  0.012048  0.084337   \n",
      "62982   0.076923  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "97964   0.139130  0.026087  0.017391  0.017391  0.104348  0.034783  0.095652   \n",
      "61405   0.020000  0.240000  0.020000  0.060000  0.000000  0.180000  0.020000   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "63427   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000   \n",
      "147844  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "147454  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "144632  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "145875  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.250000   \n",
      "\n",
      "             403       418       331  ...  350  4    278  488  197  161  395  \\\n",
      "11377   1.000000  0.053763  0.091398  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "30766   0.650602  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "62982   0.769231  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "97964   0.043478  0.000000  0.113043  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "61405   0.860000  0.020000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...          ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "63427   0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "147844  0.500000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "147454  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "144632  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "145875  0.500000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "        347  348  228  \n",
      "11377   0.0  0.0  0.0  \n",
      "30766   0.0  0.0  0.0  \n",
      "62982   0.0  0.0  0.0  \n",
      "97964   0.0  0.0  0.0  \n",
      "61405   0.0  0.0  0.0  \n",
      "...     ...  ...  ...  \n",
      "63427   0.0  0.0  0.0  \n",
      "147844  0.0  0.0  0.0  \n",
      "147454  0.0  0.0  0.0  \n",
      "144632  0.0  0.0  0.0  \n",
      "145875  0.0  0.0  0.0  \n",
      "\n",
      "[59656 rows x 397 columns]\n"
     ]
    }
   ],
   "source": [
    "# Standard Normalization\n",
    "def standard_normalization(df):\n",
    "    return df.iloc[:,:].apply(lambda x: (x-x.mean())/ x.std(), axis=0)\n",
    "\n",
    "# Min-Max Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def minmax_normalization(df):\n",
    "    scaler = MinMaxScaler() \n",
    "    scaled_values = scaler.fit_transform(df) \n",
    "    return pd.DataFrame(index = df.index, columns = df.columns,data = scaled_values)\n",
    "\n",
    "norm_clients_data = clients_data\n",
    "if Standard_Norm:\n",
    "    norm_clients_data = standard_normalization(norm_clients_data)\n",
    "if MinMax_Norm:\n",
    "    norm_clients_data = minmax_normalization(norm_clients_data)\n",
    "\n",
    "for column in norm_clients_data:\n",
    "    if sum(norm_clients_data[column]) < univers_tresh:\n",
    "        norm_clients_data = norm_clients_data.drop(columns = column)\n",
    "\n",
    "print(norm_clients_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "0c2721b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if do_Elbow:\n",
    "    start = time()\n",
    "    \n",
    "    distorsions = []\n",
    "    for k in range(Kmin, Kmax):\n",
    "        print(k, end = ' ')\n",
    "        model = KMeans(n_clusters=k)\n",
    "        model.fit(norm_clients_data)\n",
    "        distorsions.append(model.inertia_)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    plt.plot(range(Kmin, Kmax), distorsions)\n",
    "    plt.grid(True)\n",
    "    plt.title('Elbow curve')\n",
    "    plt.show()\n",
    "    if save_fig:\n",
    "        plt.savefig(\"UC2_fig/Elbow_Curve.jpg\")\n",
    "    # environ 10s*Kmax\n",
    "    print(\"Time Taken to generate Elbow Curve : ~\" + str(int(time() - start)) + \"secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0bf09135",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if do_Elbow:\n",
    "    start = time()\n",
    "\n",
    "    distorsions = []\n",
    "    for k in range(Kmin, Kmax):\n",
    "        print(k, end = ' ')\n",
    "        model = KMeans(n_clusters=k)\n",
    "        model.fit(norm_clients_data)\n",
    "        cluster = model.predict(norm_clients_data)\n",
    "        cluster_centers = model.cluster_centers_\n",
    "\n",
    "        treshold = Standard_Tresh if Standard_Norm else MinMax_Tesh\n",
    "        NACK = 0\n",
    "        for i in range(len(cluster_centers)):\n",
    "            if sum([(1 if c > treshold else 0) for c in cluster_centers[i]]) == 0:\n",
    "                NACK += cluster.tolist().count(i)\n",
    "\n",
    "        distorsions.append(NACK/len(cluster))\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    plt.plot(range(Kmin, Kmax), distorsions)\n",
    "    plt.grid(True)\n",
    "    plt.title('Exclude Elbow curve')\n",
    "    plt.show()\n",
    "    \n",
    "    if save_fig:\n",
    "        plt.savefig(\"UC2_fig/Exclude_Elbow_Curve.jpg\")\n",
    "\n",
    "    # environ 10s*Kmax\n",
    "    print(\"Time Taken to generate Exclude Elbow Curve : ~\" + str(int(time() - start)) + \"secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "76da050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to fit model : ~29secondes\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model = KMeans(K, n_init = n_init)\n",
    "model.fit(norm_clients_data)\n",
    "cluster = model.labels_\n",
    "# environ 1.5s * n_init\n",
    "print(\"Time Taken to fit model : ~\" + str(int(time() - start)) + \"secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "24f71eb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_centers = model.cluster_centers_\n",
    "\n",
    "interest = {i:[] for i in range(len(cluster_centers))}\n",
    "\n",
    "treshold = Standard_Tresh if Standard_Norm else MinMax_Tesh\n",
    "\n",
    "for i in range(len(cluster_centers)):\n",
    "    for j in range(len(cluster_centers[i])):\n",
    "        if cluster_centers[i][j] > treshold:\n",
    "            interest[i].append(clients_data.columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b7bb7662",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cluster 0: 4.22 %\n",
      " Univ_KEY                     Univ_1                    Univ_2 Univ_3   Univ_4\n",
      "      454 APERITIF   ENTREES   TAPAS BISCUITERIE SALEE  SNACKS  CHIPS > 1 PERS\n",
      "\n",
      "\n",
      "Cluster 1: 1.49 %\n",
      " Univ_KEY   Univ_1 Univ_2 Univ_3    Univ_4\n",
      "      250 BOISSONS   VINS FRANCE LANGUEDOC\n",
      "\n",
      "\n",
      "Cluster 2: 2.13 %\n",
      " Univ_KEY         Univ_1       Univ_2        Univ_3        Univ_4\n",
      "      299 PETIT DEJEUNER VIENNOISERIE VIENNOISERIES VIENNOISERIES\n",
      "      437 PETIT DEJEUNER CAFE SERVICE  CAFE SERVICE  CAFE SERVICE\n",
      "\n",
      "\n",
      "Cluster 3: 4.48 %\n",
      " Univ_KEY        Univ_1         Univ_2         Univ_3          Univ_4\n",
      "      403 PRET A MANGER PLATS PREPARES TRADITION FOOD PLATS TRADITION\n",
      "      406 PRET A MANGER PLATS PREPARES   ITALIAN FOOD  PLATS ITALIENS\n",
      "\n",
      "\n",
      "Cluster 4: 5.35 %\n",
      " Univ_KEY         Univ_1                       Univ_2 Univ_3 Univ_4\n",
      "      297 PETIT DEJEUNER BOULANGERIE   PROD CROQUANTS  PAINS  PAINS\n",
      "\n",
      "\n",
      "Cluster 5: 12.73 %\n",
      " Univ_KEY         Univ_1       Univ_2        Univ_3        Univ_4\n",
      "      299 PETIT DEJEUNER VIENNOISERIE VIENNOISERIES VIENNOISERIES\n",
      "\n",
      "\n",
      "Cluster 6: 5.67 %\n",
      " Univ_KEY         Univ_1       Univ_2            Univ_3               Univ_4\n",
      "      299 PETIT DEJEUNER VIENNOISERIE     VIENNOISERIES        VIENNOISERIES\n",
      "      392  PRET A MANGER   SANDWICHES SANDWICHES FROIDS SANDWICHES CLASSIQUE\n",
      "      393  PRET A MANGER   SANDWICHES SANDWICHES FROIDS  SANDWICHES SPECIAUX\n",
      "\n",
      "\n",
      "Cluster 7: 5.98 %\n",
      " Univ_KEY         Univ_1                       Univ_2        Univ_3        Univ_4\n",
      "      296 PETIT DEJEUNER BOULANGERIE   PROD CROQUANTS    MINI PAINS    MINI PAINS\n",
      "      299 PETIT DEJEUNER                 VIENNOISERIE VIENNOISERIES VIENNOISERIES\n",
      "\n",
      "\n",
      "Cluster 8: 2.25 %\n",
      " Univ_KEY         Univ_1       Univ_2            Univ_3          Univ_4\n",
      "      299 PETIT DEJEUNER VIENNOISERIE     VIENNOISERIES   VIENNOISERIES\n",
      "      394  PRET A MANGER   SANDWICHES SANDWICHES FROIDS SANDWICHES MOUS\n",
      "\n",
      "\n",
      "Cluster 9: 5.0 %\n",
      " Univ_KEY          Univ_1             Univ_2             Univ_3             Univ_4\n",
      "      272 TABACS   PRESSE TABAC   CIGARETTES TABAC   CIGARETTES TABAC   CIGARETTES\n",
      "      299  PETIT DEJEUNER       VIENNOISERIE      VIENNOISERIES      VIENNOISERIES\n",
      "\n",
      "\n",
      "Cluster 10: 3.6 %\n",
      " Univ_KEY        Univ_1        Univ_2             Univ_3             Univ_4\n",
      "      189      BOISSONS        BIERES BLONDE (HORS PILS) BLONDE (HORS PILS)\n",
      "      388 CONSIGNE PLUS CONSIGNE PLUS       VIDANGE PLUS       VIDANGE PLUS\n",
      "\n",
      "\n",
      "Cluster 11: 4.76 %\n",
      " Univ_KEY   Univ_1      Univ_2 Univ_3 Univ_4\n",
      "      457 BOISSONS SOFT DRINKS   SODA  COLAS\n",
      "\n",
      "\n",
      "Cluster 12: 2.87 %\n",
      " Univ_KEY                     Univ_1                       Univ_2        Univ_3         Univ_4\n",
      "      294             PETIT DEJEUNER BOULANGERIE   PROD CROQUANTS     BAGUETTES      BAGUETTES\n",
      "      296             PETIT DEJEUNER BOULANGERIE   PROD CROQUANTS    MINI PAINS     MINI PAINS\n",
      "      297             PETIT DEJEUNER BOULANGERIE   PROD CROQUANTS         PAINS          PAINS\n",
      "      299             PETIT DEJEUNER                 VIENNOISERIE VIENNOISERIES  VIENNOISERIES\n",
      "      406              PRET A MANGER               PLATS PREPARES  ITALIAN FOOD PLATS ITALIENS\n",
      "      454 APERITIF   ENTREES   TAPAS    BISCUITERIE SALEE  SNACKS         CHIPS       > 1 PERS\n",
      "      457                   BOISSONS                  SOFT DRINKS          SODA          COLAS\n",
      "\n",
      "\n",
      "Cluster 13: 3.55 %\n",
      " Univ_KEY        Univ_1         Univ_2       Univ_3       Univ_4\n",
      "      402 PRET A MANGER PLATS PREPARES CHINESE FOOD CHINESE FOOD\n",
      "      412 PRET A MANGER PLATS PREPARES    THAI FOOD    THAI FOOD\n",
      "\n",
      "\n",
      "Cluster 14: 4.19 %\n",
      " Univ_KEY         Univ_1                       Univ_2    Univ_3    Univ_4\n",
      "      294 PETIT DEJEUNER BOULANGERIE   PROD CROQUANTS BAGUETTES BAGUETTES\n",
      "\n",
      "\n",
      "Cluster 15: 6.19 %\n",
      " Univ_KEY        Univ_1         Univ_2       Univ_3         Univ_4\n",
      "      406 PRET A MANGER PLATS PREPARES ITALIAN FOOD PLATS ITALIENS\n",
      "\n",
      "\n",
      "Cluster 16: 9.59 %\n",
      "\n",
      "\n",
      "Cluster 17: 3.67 %\n",
      " Univ_KEY           Univ_1  Univ_2         Univ_3   Univ_4\n",
      "      171 FRUITS   LEGUMES  FRUITS       EXOTIQUE EXOTIQUE\n",
      "      183 FRUITS   LEGUMES LEGUMES AUTRES LEGUMES   FRUITS\n",
      "\n",
      "\n",
      "Cluster 18: 6.84 %\n",
      " Univ_KEY        Univ_1         Univ_2         Univ_3          Univ_4\n",
      "      403 PRET A MANGER PLATS PREPARES TRADITION FOOD PLATS TRADITION\n",
      "\n",
      "\n",
      "Cluster 19: 3.56 %\n",
      " Univ_KEY         Univ_1         Univ_2         Univ_3          Univ_4\n",
      "      299 PETIT DEJEUNER   VIENNOISERIE  VIENNOISERIES   VIENNOISERIES\n",
      "      403  PRET A MANGER PLATS PREPARES TRADITION FOOD PLATS TRADITION\n",
      "      406  PRET A MANGER PLATS PREPARES   ITALIAN FOOD  PLATS ITALIENS\n",
      "\n",
      "\n",
      "Cluster 20: 1.89 %\n",
      " Univ_KEY  Univ_1     Univ_2                Univ_3                Univ_4\n",
      "      148 DESSERT PATISSERIE PATISSERIE INDIVIVUEL PATISSERIE INDIVIVUEL\n",
      "\n",
      "NACK = 9.59 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NACK = 0\n",
    "\n",
    "conn = pyodbc.connect(login)\n",
    "for key,values in interest.items():\n",
    "    print(\"\\n\\nCluster\", key, end=': ')\n",
    "    proportion = cluster.tolist().count(key)*100/len(cluster)\n",
    "    print(round(proportion,2),\"%\",)\n",
    "    \n",
    "    if len(values) == 0:\n",
    "        NACK += proportion\n",
    "        continue\n",
    "    \n",
    "    sql_command = '''SELECT [''' + TABLE_UNIVERS  + '''.KEY] AS Univ_KEY,\n",
    "    [''' + TABLE_UNIVERS  + '''.Libelle_univers1_FR] AS Univ_1, \n",
    "    [''' + TABLE_UNIVERS  + '''.Libelle_univers2_FR] AS Univ_2, \n",
    "    [''' + TABLE_UNIVERS  + '''.Libelle_univers3_FR] AS Univ_3, \n",
    "    [''' + TABLE_UNIVERS  + '''.Libelle_univers4_FR] AS Univ_4\n",
    "    FROM ['''+DB+'''].[DWH].[Dim_'''+TABLE_UNIVERS+''']\n",
    "    WHERE '''\n",
    "    for v in values:\n",
    "        sql_command += \"[\" + TABLE_UNIVERS  + \".KEY] = \" + str(v) + \"\\nOR \"\n",
    "    sql_command = sql_command[:-3]\n",
    "    #print(sql_command)\n",
    "\n",
    "    df_libele = pd.read_sql(sql_command, conn)\n",
    "    print(df_libele.to_string(index=False))\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nNACK =\", round(NACK,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87defe84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7b606702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken: ~439secondes\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Time Taken: ~\" + str(int(time() - Very_Start)) + \"secondes\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
